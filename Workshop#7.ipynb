{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop # 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"titanic-train.csv\")\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch\n",
       "0         0       3    male  22.0      1      0\n",
       "1         1       1  female  38.0      1      0\n",
       "2         1       3  female  26.0      0      0\n",
       "3         1       1  female  35.0      1      0\n",
       "4         0       3    male  35.0      0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.loc[:,['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch']]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "      <td>424</td>\n",
       "      <td>549</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "      <td>290</td>\n",
       "      <td>342</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pclass  Sex  Age  SibSp  Parch\n",
       "Survived                                \n",
       "0            549  549  424    549    549\n",
       "1            342  342  290    342    342"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('Survived').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age missing  177\n",
      "PClass missing  0\n",
      "SibSp missing  0\n",
      "Parch missing  0\n",
      "Survived missing  0\n"
     ]
    }
   ],
   "source": [
    "print('Age missing ', df2['Age'].isnull().sum())\n",
    "print('PClass missing ', df2['Pclass'].isnull().sum())\n",
    "print('SibSp missing ', df2['SibSp'].isnull().sum())\n",
    "print('Parch missing ', df2['Parch'].isnull().sum())\n",
    "print('Survived missing ', df2['Survived'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age missing  0\n"
     ]
    }
   ],
   "source": [
    "df2['Age'] = df2['Age'].fillna(df2['Age'].mean())\n",
    "\n",
    "print('Age missing ', df2['Age'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch  Sex_female  Sex_male\n",
       "0         0       3  22.0      1      0       False      True\n",
       "1         1       1  38.0      1      0        True     False\n",
       "2         1       3  26.0      0      0        True     False\n",
       "3         1       1  35.0      1      0        True     False\n",
       "4         0       3  35.0      0      0       False      True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.get_dummies(df2)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels for training and testing data\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(df3[['Pclass','Sex_female','Sex_male','Age','SibSp','Parch']], \n",
    "                                                    df3['Survived'], \n",
    "                                                    train_size=0.7, \n",
    "                                                    random_state=123)\n",
    "print(\"Labels for training and testing data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.38650536  1.34398895 -1.34398895  0.32679126  0.42278951  0.80910353]\n",
      " [-0.38650536  1.34398895 -1.34398895  0.09075797  0.42278951  0.80910353]\n",
      " [-1.59046957 -0.74405373  0.74405373  0.48414679 -0.45228645 -0.46702685]\n",
      " ...\n",
      " [ 0.81745884 -0.74405373  0.74405373  0.16943573 -0.45228645 -0.46702685]\n",
      " [ 0.81745884 -0.74405373  0.74405373  0.01208021 -0.45228645 -0.46702685]\n",
      " [ 0.81745884 -0.74405373  0.74405373 -0.06659756 -0.45228645 -0.46702685]]\n",
      "416    1\n",
      "801    1\n",
      "512    1\n",
      "455    1\n",
      "757    0\n",
      "      ..\n",
      "98     1\n",
      "322    1\n",
      "382    0\n",
      "365    0\n",
      "510    1\n",
      "Name: Survived, Length: 623, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_X)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on MLPClassifier in module sklearn.neural_network._multilayer_perceptron object:\n",
      "\n",
      "class MLPClassifier(sklearn.base.ClassifierMixin, BaseMultilayerPerceptron)\n",
      " |  MLPClassifier(hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |  \n",
      " |  Multi-layer Perceptron classifier.\n",
      " |  \n",
      " |  This model optimizes the log-loss function using LBFGS or stochastic\n",
      " |  gradient descent.\n",
      " |  \n",
      " |  .. versionadded:: 0.18\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  hidden_layer_sizes : array-like of shape(n_layers - 2,), default=(100,)\n",
      " |      The ith element represents the number of neurons in the ith\n",
      " |      hidden layer.\n",
      " |  \n",
      " |  activation : {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
      " |      Activation function for the hidden layer.\n",
      " |  \n",
      " |      - 'identity', no-op activation, useful to implement linear bottleneck,\n",
      " |        returns f(x) = x\n",
      " |  \n",
      " |      - 'logistic', the logistic sigmoid function,\n",
      " |        returns f(x) = 1 / (1 + exp(-x)).\n",
      " |  \n",
      " |      - 'tanh', the hyperbolic tan function,\n",
      " |        returns f(x) = tanh(x).\n",
      " |  \n",
      " |      - 'relu', the rectified linear unit function,\n",
      " |        returns f(x) = max(0, x)\n",
      " |  \n",
      " |  solver : {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
      " |      The solver for weight optimization.\n",
      " |  \n",
      " |      - 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
      " |  \n",
      " |      - 'sgd' refers to stochastic gradient descent.\n",
      " |  \n",
      " |      - 'adam' refers to a stochastic gradient-based optimizer proposed\n",
      " |        by Kingma, Diederik, and Jimmy Ba\n",
      " |  \n",
      " |      Note: The default solver 'adam' works pretty well on relatively\n",
      " |      large datasets (with thousands of training samples or more) in terms of\n",
      " |      both training time and validation score.\n",
      " |      For small datasets, however, 'lbfgs' can converge faster and perform\n",
      " |      better.\n",
      " |  \n",
      " |  alpha : float, default=0.0001\n",
      " |      Strength of the L2 regularization term. The L2 regularization term\n",
      " |      is divided by the sample size when added to the loss.\n",
      " |  \n",
      " |  batch_size : int, default='auto'\n",
      " |      Size of minibatches for stochastic optimizers.\n",
      " |      If the solver is 'lbfgs', the classifier will not use minibatch.\n",
      " |      When set to \"auto\", `batch_size=min(200, n_samples)`.\n",
      " |  \n",
      " |  learning_rate : {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
      " |      Learning rate schedule for weight updates.\n",
      " |  \n",
      " |      - 'constant' is a constant learning rate given by\n",
      " |        'learning_rate_init'.\n",
      " |  \n",
      " |      - 'invscaling' gradually decreases the learning rate at each\n",
      " |        time step 't' using an inverse scaling exponent of 'power_t'.\n",
      " |        effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
      " |  \n",
      " |      - 'adaptive' keeps the learning rate constant to\n",
      " |        'learning_rate_init' as long as training loss keeps decreasing.\n",
      " |        Each time two consecutive epochs fail to decrease training loss by at\n",
      " |        least tol, or fail to increase validation score by at least tol if\n",
      " |        'early_stopping' is on, the current learning rate is divided by 5.\n",
      " |  \n",
      " |      Only used when ``solver='sgd'``.\n",
      " |  \n",
      " |  learning_rate_init : float, default=0.001\n",
      " |      The initial learning rate used. It controls the step-size\n",
      " |      in updating the weights. Only used when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  power_t : float, default=0.5\n",
      " |      The exponent for inverse scaling learning rate.\n",
      " |      It is used in updating effective learning rate when the learning_rate\n",
      " |      is set to 'invscaling'. Only used when solver='sgd'.\n",
      " |  \n",
      " |  max_iter : int, default=200\n",
      " |      Maximum number of iterations. The solver iterates until convergence\n",
      " |      (determined by 'tol') or this number of iterations. For stochastic\n",
      " |      solvers ('sgd', 'adam'), note that this determines the number of epochs\n",
      " |      (how many times each data point will be used), not the number of\n",
      " |      gradient steps.\n",
      " |  \n",
      " |  shuffle : bool, default=True\n",
      " |      Whether to shuffle samples in each iteration. Only used when\n",
      " |      solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Determines random number generation for weights and bias\n",
      " |      initialization, train-test split if early stopping is used, and batch\n",
      " |      sampling when solver='sgd' or 'adam'.\n",
      " |      Pass an int for reproducible results across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for the optimization. When the loss or score is not improving\n",
      " |      by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,\n",
      " |      unless ``learning_rate`` is set to 'adaptive', convergence is\n",
      " |      considered to be reached and training stops.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Whether to print progress messages to stdout.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous\n",
      " |      call to fit as initialization, otherwise, just erase the\n",
      " |      previous solution. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  momentum : float, default=0.9\n",
      " |      Momentum for gradient descent update. Should be between 0 and 1. Only\n",
      " |      used when solver='sgd'.\n",
      " |  \n",
      " |  nesterovs_momentum : bool, default=True\n",
      " |      Whether to use Nesterov's momentum. Only used when solver='sgd' and\n",
      " |      momentum > 0.\n",
      " |  \n",
      " |  early_stopping : bool, default=False\n",
      " |      Whether to use early stopping to terminate training when validation\n",
      " |      score is not improving. If set to true, it will automatically set\n",
      " |      aside 10% of training data as validation and terminate training when\n",
      " |      validation score is not improving by at least tol for\n",
      " |      ``n_iter_no_change`` consecutive epochs. The split is stratified,\n",
      " |      except in a multilabel setting.\n",
      " |      If early stopping is False, then the training stops when the training\n",
      " |      loss does not improve by more than tol for n_iter_no_change consecutive\n",
      " |      passes over the training set.\n",
      " |      Only effective when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  validation_fraction : float, default=0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Must be between 0 and 1.\n",
      " |      Only used if early_stopping is True.\n",
      " |  \n",
      " |  beta_1 : float, default=0.9\n",
      " |      Exponential decay rate for estimates of first moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'.\n",
      " |  \n",
      " |  beta_2 : float, default=0.999\n",
      " |      Exponential decay rate for estimates of second moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'.\n",
      " |  \n",
      " |  epsilon : float, default=1e-8\n",
      " |      Value for numerical stability in adam. Only used when solver='adam'.\n",
      " |  \n",
      " |  n_iter_no_change : int, default=10\n",
      " |      Maximum number of epochs to not meet ``tol`` improvement.\n",
      " |      Only effective when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  max_fun : int, default=15000\n",
      " |      Only used when solver='lbfgs'. Maximum number of loss function calls.\n",
      " |      The solver iterates until convergence (determined by 'tol'), number\n",
      " |      of iterations reaches max_iter, or this number of loss function calls.\n",
      " |      Note that number of loss function calls will be greater than or equal\n",
      " |      to the number of iterations for the `MLPClassifier`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : ndarray or list of ndarray of shape (n_classes,)\n",
      " |      Class labels for each output.\n",
      " |  \n",
      " |  loss_ : float\n",
      " |      The current loss computed with the loss function.\n",
      " |  \n",
      " |  best_loss_ : float or None\n",
      " |      The minimum loss reached by the solver throughout fitting.\n",
      " |      If `early_stopping=True`, this attribute is set ot `None`. Refer to\n",
      " |      the `best_validation_score_` fitted attribute instead.\n",
      " |  \n",
      " |  loss_curve_ : list of shape (`n_iter_`,)\n",
      " |      The ith element in the list represents the loss at the ith iteration.\n",
      " |  \n",
      " |  validation_scores_ : list of shape (`n_iter_`,) or None\n",
      " |      The score at each iteration on a held-out validation set. The score\n",
      " |      reported is the accuracy score. Only available if `early_stopping=True`,\n",
      " |      otherwise the attribute is set to `None`.\n",
      " |  \n",
      " |  best_validation_score_ : float or None\n",
      " |      The best validation score (i.e. accuracy score) that triggered the\n",
      " |      early stopping. Only available if `early_stopping=True`, otherwise the\n",
      " |      attribute is set to `None`.\n",
      " |  \n",
      " |  t_ : int\n",
      " |      The number of training samples seen by the solver during fitting.\n",
      " |  \n",
      " |  coefs_ : list of shape (n_layers - 1,)\n",
      " |      The ith element in the list represents the weight matrix corresponding\n",
      " |      to layer i.\n",
      " |  \n",
      " |  intercepts_ : list of shape (n_layers - 1,)\n",
      " |      The ith element in the list represents the bias vector corresponding to\n",
      " |      layer i + 1.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      The number of iterations the solver has run.\n",
      " |  \n",
      " |  n_layers_ : int\n",
      " |      Number of layers.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      Number of outputs.\n",
      " |  \n",
      " |  out_activation_ : str\n",
      " |      Name of the output activation function.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  MLPRegressor : Multi-layer Perceptron regressor.\n",
      " |  BernoulliRBM : Bernoulli Restricted Boltzmann Machine (RBM).\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  MLPClassifier trains iteratively since at each time step\n",
      " |  the partial derivatives of the loss function with respect to the model\n",
      " |  parameters are computed to update the parameters.\n",
      " |  \n",
      " |  It can also have a regularization term added to the loss function\n",
      " |  that shrinks model parameters to prevent overfitting.\n",
      " |  \n",
      " |  This implementation works with data represented as dense numpy arrays or\n",
      " |  sparse scipy arrays of floating point values.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Hinton, Geoffrey E. \"Connectionist learning procedures.\"\n",
      " |  Artificial intelligence 40.1 (1989): 185-234.\n",
      " |  \n",
      " |  Glorot, Xavier, and Yoshua Bengio.\n",
      " |  \"Understanding the difficulty of training deep feedforward neural networks.\"\n",
      " |  International Conference on Artificial Intelligence and Statistics. 2010.\n",
      " |  \n",
      " |  :arxiv:`He, Kaiming, et al (2015). \"Delving deep into rectifiers:\n",
      " |  Surpassing human-level performance on imagenet classification.\" <1502.01852>`\n",
      " |  \n",
      " |  :arxiv:`Kingma, Diederik, and Jimmy Ba (2014)\n",
      " |  \"Adam: A method for stochastic optimization.\" <1412.6980>`\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.neural_network import MLPClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> from sklearn.model_selection import train_test_split\n",
      " |  >>> X, y = make_classification(n_samples=100, random_state=1)\n",
      " |  >>> X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
      " |  ...                                                     random_state=1)\n",
      " |  >>> clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
      " |  >>> clf.predict_proba(X_test[:1])\n",
      " |  array([[0.038..., 0.961...]])\n",
      " |  >>> clf.predict(X_test[:5, :])\n",
      " |  array([1, 0, 1, 0, 1])\n",
      " |  >>> clf.score(X_test, y_test)\n",
      " |  0.8...\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MLPClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseMultilayerPerceptron\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  partial_fit(self, X, y, classes=None)\n",
      " |      Update the model with a single iteration over the given data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target values.\n",
      " |      \n",
      " |      classes : array of shape (n_classes,), default=None\n",
      " |          Classes across all calls to partial_fit.\n",
      " |          Can be obtained via `np.unique(y_all)`, where y_all is the\n",
      " |          target vector of the entire dataset.\n",
      " |          This argument is required for the first call to partial_fit\n",
      " |          and can be omitted in the subsequent calls.\n",
      " |          Note that y doesn't need to contain all labels in `classes`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Trained MLP model.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the multi-layer perceptron classifier.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray, shape (n_samples,) or (n_samples, n_classes)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Return the log of probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      log_y_prob : ndarray of shape (n_samples, n_classes)\n",
      " |          The predicted log-probability of the sample for each class\n",
      " |          in the model, where classes are ordered as they are in\n",
      " |          `self.classes_`. Equivalent to `log(predict_proba(X))`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_prob : ndarray of shape (n_samples, n_classes)\n",
      " |          The predicted probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in `self.classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseMultilayerPerceptron:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model to data matrix X and target(s) y.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray or sparse matrix of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(3),solver='sgd',activation='relu',\n",
    "                    random_state=150,learning_rate_init=0.01,max_iter=1000)\n",
    "help(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=3, learning_rate_init=0.01, max_iter=1000,\n",
       "              random_state=150, solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=3, learning_rate_init=0.01, max_iter=1000,\n",
       "              random_state=150, solver=&#x27;sgd&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=3, learning_rate_init=0.01, max_iter=1000,\n",
       "              random_state=150, solver='sgd')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Titanic on the test set using Multi-Layer Precepiton\n",
      "Accurary :  0.8134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86       170\n",
      "           1       0.76      0.71      0.74        98\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.80      0.79      0.80       268\n",
      "weighted avg       0.81      0.81      0.81       268\n",
      "\n",
      "[[148  22]\n",
      " [ 28  70]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Predicting Titanic on the test set using Multi-Layer Precepiton\")\n",
    "\n",
    "y_pred = mlp.predict(test_X)\n",
    "\n",
    "print(\"Accurary : \", round(accuracy_score(test_y, y_pred),4))\n",
    "print(classification_report(test_y, y_pred))\n",
    "print(confusion_matrix(test_y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIhCAYAAAAimCCiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/J0lEQVR4nO3dfZzM9f7/8efs1axddtl17FrtuiZXsVYcJOSqTeTohKiIRFTW9ZFTS8WyXydbLiNa1+oUTrqkFIrKZUVSTouUPZuIrLX24vP7o5v5Nd5ol5mdYR73bnM7zfvzmc+8Zm6p13m+35/32CzLsgQAAAD8gZ+nCwAAAID3oUkEAACAgSYRAAAABppEAAAAGGgSAQAAYKBJBAAAgIEmEQAAAAaaRAAAABhoEgEAAGCgSQSuAV9++aUefPBBVa1aVcHBwSpdurQaN26s1NRUHT9+3K3vvWvXLrVu3Vrh4eGy2WxKS0tz+XvYbDZNmDDB5df9M+np6bLZbLLZbProo4+M45ZlqUaNGrLZbGrTps0Vvcfs2bOVnp5erNd89NFHl6wJAEpKgKcLAHB58+fP15AhQ1S7dm2NHj1adevWVV5enrZv3665c+dq69atWr16tdvev3///srOztbKlStVrlw5ValSxeXvsXXrVt1www0uv25RlSlTRgsWLDAawY0bN+q///2vypQpc8XXnj17tsqXL69+/foV+TWNGzfW1q1bVbdu3St+XwC4WjSJgBfbunWrHnnkEXXo0EFr1qyR3W53HOvQoYNGjhypd99916017NmzRwMHDlRiYqLb3uOvf/2r265dFD179tSyZcs0a9YshYWFOcYXLFig5s2b69SpUyVSR15enmw2m8LCwjz+nQAA082AF5s8ebJsNpvmzZvn1CCeFxQUpK5duzqeFxYWKjU1VTfeeKPsdrsqVKigBx54QEeOHHF6XZs2bVS/fn1t27ZNrVq1UkhIiKpVq6YpU6aosLBQ0v+fis3Pz9ecOXMc07KSNGHCBMff/9H51xw8eNAxtmHDBrVp00aRkZEqVaqU4uLidPfdd+vMmTOOcy423bxnzx7dddddKleunIKDg9WoUSMtWrTI6Zzz07IrVqzQ+PHjFRMTo7CwMLVv31779+8v2pcs6d5775UkrVixwjF28uRJvf766+rfv/9FXzNx4kQ1a9ZMERERCgsLU+PGjbVgwQJZluU4p0qVKtq7d682btzo+P7OJ7Hna1+yZIlGjhypSpUqyW6368CBA8Z087FjxxQbG6sWLVooLy/Pcf2vv/5aoaGhuv/++4v8WQGgqGgSAS9VUFCgDRs2KCEhQbGxsUV6zSOPPKKxY8eqQ4cOeuONN/TMM8/o3XffVYsWLXTs2DGnczMzM9WnTx/dd999euONN5SYmKhx48Zp6dKlkqTOnTtr69atkqS///3v2rp1q+N5UR08eFCdO3dWUFCQFi5cqHfffVdTpkxRaGiozp07d8nX7d+/Xy1atNDevXv1wgsvaNWqVapbt6769eun1NRU4/wnnnhChw4d0ksvvaR58+bpu+++U5cuXVRQUFCkOsPCwvT3v/9dCxcudIytWLFCfn5+6tmz5yU/26BBg/Tqq69q1apV6t69ux577DE988wzjnNWr16tatWqKT4+3vH9Xbg0YNy4cTp8+LDmzp2rtWvXqkKFCsZ7lS9fXitXrtS2bds0duxYSdKZM2d0zz33KC4uTnPnzi3S5wSAYrEAeKXMzExLktWrV68inb9v3z5LkjVkyBCn8c8++8ySZD3xxBOOsdatW1uSrM8++8zp3Lp161qdOnVyGpNkDR061GksOTnZuti/Pl5++WVLkpWRkWFZlmW99tprliRr9+7dl61dkpWcnOx43qtXL8tut1uHDx92Oi8xMdEKCQmxfv31V8uyLOvDDz+0JFl33HGH03mvvvqqJcnaunXrZd/3fL3btm1zXGvPnj2WZVnWzTffbPXr18+yLMuqV6+e1bp160tep6CgwMrLy7OefvppKzIy0iosLHQcu9Rrz7/frbfeesljH374odP41KlTLUnW6tWrrb59+1qlSpWyvvzyy8t+RgC4UiSJwHXiww8/lCTjBommTZuqTp06+uCDD5zGo6Oj1bRpU6exm266SYcOHXJZTY0aNVJQUJAefvhhLVq0SN9//32RXrdhwwa1a9fOSFD79eunM2fOGInmH6fcpd8/h6RifZbWrVurevXqWrhwob766itt27btklPN52ts3769wsPD5e/vr8DAQD311FP65ZdflJWVVeT3vfvuu4t87ujRo9W5c2fde++9WrRokWbMmKEGDRoU+fUAUBw0iYCXKl++vEJCQpSRkVGk83/55RdJUsWKFY1jMTExjuPnRUZGGufZ7Xbl5ORcQbUXV716db3//vuqUKGChg4dqurVq6t69ep6/vnnL/u6X3755ZKf4/zxP7rws5xfv1mcz2Kz2fTggw9q6dKlmjt3rmrVqqVWrVpd9NzPP/9cHTt2lPT73eeffPKJtm3bpvHjxxf7fS/2OS9XY79+/XT27FlFR0ezFhGAW9EkAl7K399f7dq1044dO4wbTy7mfKN09OhR49hPP/2k8uXLu6y24OBgSVJubq7T+IXrHiWpVatWWrt2rU6ePKlPP/1UzZs3V1JSklauXHnJ60dGRl7yc0hy6Wf5o379+unYsWOaO3euHnzwwUuet3LlSgUGBurNN99Ujx491KJFCzVp0uSK3vNiNwBdytGjRzV06FA1atRIv/zyi0aNGnVF7wkARUGTCHixcePGybIsDRw48KI3euTl5Wnt2rWSpNtuu02SHDeenLdt2zbt27dP7dq1c1ld5+/Q/fLLL53Gz9dyMf7+/mrWrJlmzZolSdq5c+clz23Xrp02bNjgaArPW7x4sUJCQty2PUylSpU0evRodenSRX379r3keTabTQEBAfL393eM5eTkaMmSJca5rkpnCwoKdO+998pms+mdd95RSkqKZsyYoVWrVl31tQHgYtgnEfBizZs315w5czRkyBAlJCTokUceUb169ZSXl6ddu3Zp3rx5ql+/vrp06aLatWvr4Ycf1owZM+Tn56fExEQdPHhQTz75pGJjYzV8+HCX1XXHHXcoIiJCAwYM0NNPP62AgAClp6frhx9+cDpv7ty52rBhgzp37qy4uDidPXvWcQdx+/btL3n95ORkvfnmm2rbtq2eeuopRUREaNmyZXrrrbeUmpqq8PBwl32WC02ZMuVPz+ncubOee+459e7dWw8//LB++eUXTZs27aLbFDVo0EArV67UK6+8omrVqik4OPiK1hEmJydr8+bNWrdunaKjozVy5Eht3LhRAwYMUHx8vKpWrVrsawLA5dAkAl5u4MCBatq0qaZPn66pU6cqMzNTgYGBqlWrlnr37q1HH33Uce6cOXNUvXp1LViwQLNmzVJ4eLhuv/12paSkXHQN4pUKCwvTu+++q6SkJN13330qW7asHnroISUmJuqhhx5ynNeoUSOtW7dOycnJyszMVOnSpVW/fn298cYbjjV9F1O7dm1t2bJFTzzxhIYOHaqcnBzVqVNHL7/8crF+ucRdbrvtNi1cuFBTp05Vly5dVKlSJQ0cOFAVKlTQgAEDnM6dOHGijh49qoEDB+q3335T5cqVnfaRLIr169crJSVFTz75pFMinJ6ervj4ePXs2VMff/yxgoKCXPHxAECSZLOsP+z8CgAAAIg1iQAAALgImkQAAAAYaBIBAABgoEkEAACAgSYRAAAABppEAAAAGGgSAQAAYLguN9MuFf/on58E4Jr00yfPe7oEAG5SLsT/z09yE3f2Djm7Zrrt2u5EkggAAADDdZkkAgAAFIuN3OxCNIkAAAA2m6cr8Dq0zQAAADCQJAIAADDdbOAbAQAAgIEkEQAAgDWJBpJEAAAAGEgSAQAAWJNo4BsBAACAgSQRAACANYkGmkQAAACmmw18IwAAADCQJAIAADDdbCBJBAAAgIEkEQAAgDWJBr4RAAAAGEgSAQAAWJNoIEkEAACAgSQRAACANYkGmkQAAACmmw20zQAAADCQJAIAADDdbOAbAQAAgIEmEQAAwObnvkcxbdq0SV26dFFMTIxsNpvWrFlzyXMHDRokm82mtLQ0p/Hc3Fw99thjKl++vEJDQ9W1a1cdOXKkWHXQJAIAAHiR7OxsNWzYUDNnzrzseWvWrNFnn32mmJgY41hSUpJWr16tlStX6uOPP9bp06d15513qqCgoMh1sCYRAADAz3vubk5MTFRiYuJlz/nxxx/16KOP6r333lPnzp2djp08eVILFizQkiVL1L59e0nS0qVLFRsbq/fff1+dOnUqUh0kiQAAAG6Um5urU6dOOT1yc3Ov+HqFhYW6//77NXr0aNWrV884vmPHDuXl5aljx46OsZiYGNWvX19btmwp8vvQJAIAALhxTWJKSorCw8OdHikpKVdc6tSpUxUQEKDHH3/8osczMzMVFBSkcuXKOY1HRUUpMzOzyO/DdDMAAIAbN9MeN26cRowY4TRmt9uv6Fo7duzQ888/r507d8pWzJotyyrWa0gSAQAA3MhutyssLMzpcaVN4ubNm5WVlaW4uDgFBAQoICBAhw4d0siRI1WlShVJUnR0tM6dO6cTJ044vTYrK0tRUVFFfi+aRAAAAC/aAudy7r//fn355ZfavXu34xETE6PRo0frvffekyQlJCQoMDBQ69evd7zu6NGj2rNnj1q0aFHk92K6GQAAwIucPn1aBw4ccDzPyMjQ7t27FRERobi4OEVGRjqdHxgYqOjoaNWuXVuSFB4ergEDBmjkyJGKjIxURESERo0apQYNGjjudi4KmkQAAAA3rkksru3bt6tt27aO5+fXM/bt21fp6elFusb06dMVEBCgHj16KCcnR+3atVN6err8/f2LXIfNsiyrWJVfA0rFP+rpEgC4yU+fPO/pEgC4SbmQojcwrlaqw1S3XTtn/Vi3XdudSBIBAABcvHbwesA3AgAAAANJIgAAgBetSfQWNIkAAABMNxv4RgAAAGAgSQQAAGC62UCSCAAAAANJIgAAAGsSDXwjAAAAMJAkAgAAsCbRQJIIAAAAA0kiAAAAaxINNIkAAAA0iQa+EQAAABhIEgEAALhxxUCSCAAAAANJIgAAAGsSDXwjAAAAMJAkAgAAsCbRQJIIAAAAA0kiAAAAaxINNIkAAABMNxtomwEAAGAgSQQAAD7PRpJoIEkEAACAgSQRAAD4PJJEE0kiAAAADCSJAAAABIkGkkQAAAAYSBIBAIDPY02iiSYRAAD4PJpEE9PNAAAAMJAkAgAAn0eSaCJJBAAAgIEkEQAA+DySRBNJIgAAAAwkiQAAAASJBpJEAAAAGEgSAQCAz2NNookkEQAAAAaSRAAA4PNIEk00iQAAwOfRJJqYbgYAAICBJBEAAPg8kkQTSSIAAAAMJIkAAAAEiQaSRAAAABhIEgEAgM9jTaKJJBEAAAAGkkQAAODzSBJNNIkAAMDn0SSamG4GAACAgSQRAACAINFAkggAAAADSSIAAPB5rEk0kSQCAADAQJIIAAB8HkmiiSQRAAAABpJEAADg80gSTTSJAADA59EkmphuBgAAgIEkEQAAgCDRQJIIAADgRTZt2qQuXbooJiZGNptNa9ascRzLy8vT2LFj1aBBA4WGhiomJkYPPPCAfvrpJ6dr5Obm6rHHHlP58uUVGhqqrl276siRI8WqgyYRAAD4PJvN5rZHcWVnZ6thw4aaOXOmcezMmTPauXOnnnzySe3cuVOrVq3St99+q65duzqdl5SUpNWrV2vlypX6+OOPdfr0ad15550qKCgoch1MNwMAAHiRxMREJSYmXvRYeHi41q9f7zQ2Y8YMNW3aVIcPH1ZcXJxOnjypBQsWaMmSJWrfvr0kaenSpYqNjdX777+vTp06FakOkkQAAODz3Jkk5ubm6tSpU06P3Nxcl9V+8uRJ2Ww2lS1bVpK0Y8cO5eXlqWPHjo5zYmJiVL9+fW3ZsqXI16VJBAAAcKOUlBSFh4c7PVJSUlxy7bNnz+of//iHevfurbCwMElSZmamgoKCVK5cOadzo6KilJmZWeRrM90MAAB8njv3SRw3bpxGjBjhNGa326/6unl5eerVq5cKCws1e/bsPz3fsqxifU6aRAAAADdugWO3213SFP5RXl6eevTooYyMDG3YsMGRIkpSdHS0zp07pxMnTjiliVlZWWrRokWR34PpZgAAgGvI+Qbxu+++0/vvv6/IyEin4wkJCQoMDHS6weXo0aPas2dPsZpEkkQAAODzvOln+U6fPq0DBw44nmdkZGj37t2KiIhQTEyM/v73v2vnzp168803VVBQ4FhnGBERoaCgIIWHh2vAgAEaOXKkIiMjFRERoVGjRqlBgwaOu52LgiYRAADAi2zfvl1t27Z1PD+/nrFv376aMGGC3njjDUlSo0aNnF734Ycfqk2bNpKk6dOnKyAgQD169FBOTo7atWun9PR0+fv7F7kOm2VZ1tV9FO9TKv5RT5cAwE1++uR5T5cAwE3KhRS9gXG1yo+vddu1D73QxW3XdifWJAIAAMBAkwiv1LJxdb2WNkjfr5uknF0z1aXNTZc8d8b4XsrZNVOP9m7jNB4VWUYLnnlAGesn69iWf2nL8rH6W/tG7i0cQLEsWjBPD/bpodtaNlHibbdozPBHdehghtM5Z85ka9qUZ9WlU1u1/mu8ena/U6+/utJDFeN65U0/y+ctaBLhlUJL2fXVtz9q+JRXL3telzY36eYGVfRT1q/GsQXP9lWtKhV0T9KLanLPZP1nw24tmdJfDWvf4KaqARTXrp3bdXfPe/XS4hV6Yc5LKigo0LBHHlJOzhnHOWnTpurTLZs1YdJUrVj1pu7t84CeS52kTR9+4MHKgesfTSK80rpPvtbE2W/qPxu+uOQ5MX8J1/R/3KMHn0hXXr75g+XNbqqq2Ss3avveQzr44y+a+tJ7+vW3HDWqE+vO0gEUQ9qsebqz699UrXpN1ax9o/45YZIyM4/qm6+/dpyz58vduuPObkpo0lQxMZXU7e4eqlGrtvZ9vdeDleN6Q5JooknENclms2nBsw9o+qIPtO/7i//E0JZd/9XfOyaoXFiIbDab7umUIHtQgDZt/66EqwVQVKdP/yZJCgsPd4w1bNRYmzd+qKys/8myLO3Y9pl+OHRQzVq09FSZuB7Z3Pi4Rnn1Fjg//PCDkpOTtXDhwkuek5uba/xItlVYIJuf5+6QgvuNfLCD8gsKNWvFR5c85/5/LNSSKf3108ZU5eUV6MzZc+o5Yr4yjhwruUIBFJllWXr+X6lqGN9Y1WvUdIyPGPuEUp5OVtdObeUfECA/m01PPPWMGsUneLBa4Prn1Uni8ePHtWjRosuec7Efzc7/344SqhCeEF8nVkPvbaOHk5de9rwJQ7uoXFiIEge9oJb3peqFpRu07P/6q16NmBKqFEBxTJvyrA58t1/PpExzGn91xVLt+eoL/V/aLKUv+7ceHzFG/5fytD7/dIuHKsX1iOlmk0eTxPObQV7K999//6fXuNiPZldoNfaq6oJ3axlfXRUiSuvbt592jAUE+GvKiO56tE9b3dg5WVVvKK9HerVW47ufdUxHf/Xtj2rZuLoG9bxVj0/izkjAm0yb8qw2b/xQcxcsVoWoaMf42bNnNWdGmqY+N0MtW7WWJNWsVVvf7v9Gy5ekq+lfi/4TYwCKx6NNYrdu3WSz2XS5/bz/rAO/2I9mM9V8fVv+1jZt+Gy/09ja2UO1/K3Ptfg/n0qSQoKDJEmFF/yzVVBgye8a/n91wPXGsiz9a+okbdzwvmbNT1dMJefdBwry85Wfn2/8t8Df30+FhYUlWSquc9dy4ucuHm0SK1asqFmzZqlbt24XPb57924lJLDmxBeFlgpS9di/OJ5XqRSpm2pV0olTZ/RD5gkdP5ntdH5efoH+d+yUvjuUJUnafzBTBw5naeY/79W451brl5PZ6tr2JrX7a211Hza3RD8LgEv7v5RntO6dt5Q6faZCQ0P1y7GfJUmhpcsoODhYoaVLKz7hZs1MmyZ7cLAqVozRzh3b9M6bb+jxEcwaAe7k0SYxISFBO3fuvGST+GcpI65fjetW1rqXhjmep466W5K05I1P/3QtoiTl5xeq22Nz9Ozjd+m15wepdIhd//3hZz301BK99/HXf/p6ACVj1b9/X/oxZGBfp/F/TpykO7v+TZL07JRpmj1juiY8MUanTp1UdMUYDRo6TN3v6Vni9eL6RZBo8uhvN2/evFnZ2dm6/fbbL3o8Oztb27dvV+vWrYt1XX67Gbh+8dvNwPXLk7/dXGPUO2679oFpiW67tjt5NEls1arVZY+HhoYWu0EEAAAoLtYkmrx6n0QAAICSQI9o8up9EgEAAOAZJIkAAMDnMd1sIkkEAACAgSQRAAD4PIJEE0kiAAAADCSJAADA5/n5ESVeiCQRAAAABpJEAADg81iTaKJJBAAAPo8tcExMNwMAAMBAkggAAHweQaKJJBEAAAAGkkQAAODzWJNoIkkEAACAgSQRAAD4PJJEE0kiAAAADCSJAADA5xEkmmgSAQCAz2O62cR0MwAAAAwkiQAAwOcRJJpIEgEAAGAgSQQAAD6PNYkmkkQAAAAYSBIBAIDPI0g0kSQCAADAQJIIAAB8HmsSTSSJAAAAMJAkAgAAn0eQaKJJBAAAPo/pZhPTzQAAADCQJAIAAJ9HkGgiSQQAAICBJBEAAPg81iSaSBIBAABgIEkEAAA+jyDRRJIIAAAAA0kiAADweaxJNNEkAgAAn0ePaGK6GQAAAAaSRAAA4POYbjaRJAIAAMBAkggAAHweSaKJJBEAAAAGkkQAAODzCBJNJIkAAAAwkCQCAACfx5pEE00iAADwefSIJqabAQAAYCBJBAAAPo/pZhNJIgAAgBfZtGmTunTpopiYGNlsNq1Zs8bpuGVZmjBhgmJiYlSqVCm1adNGe/fudTonNzdXjz32mMqXL6/Q0FB17dpVR44cKVYdNIkAAMDn2WzuexRXdna2GjZsqJkzZ170eGpqqp577jnNnDlT27ZtU3R0tDp06KDffvvNcU5SUpJWr16tlStX6uOPP9bp06d15513qqCgoMh1MN0MAADgRRITE5WYmHjRY5ZlKS0tTePHj1f37t0lSYsWLVJUVJSWL1+uQYMG6eTJk1qwYIGWLFmi9u3bS5KWLl2q2NhYvf/+++rUqVOR6iBJBAAAPs/PZnPbIzc3V6dOnXJ65ObmXlGdGRkZyszMVMeOHR1jdrtdrVu31pYtWyRJO3bsUF5entM5MTExql+/vuOcIn0nV1QhAAAAiiQlJUXh4eFOj5SUlCu6VmZmpiQpKirKaTwqKspxLDMzU0FBQSpXrtwlzykKppsBAIDPc+fNzePGjdOIESOcxux2+1Vd88K7sS3L+tM7tItyzh/RJAIAAJ/nzi1w7Hb7VTeF50VHR0v6PS2sWLGiYzwrK8uRLkZHR+vcuXM6ceKEU5qYlZWlFi1aFPm9mG4GAAC4RlStWlXR0dFav369Y+zcuXPauHGjowFMSEhQYGCg0zlHjx7Vnj17itUkkiQCAACf5+dFe2mfPn1aBw4ccDzPyMjQ7t27FRERobi4OCUlJWny5MmqWbOmatasqcmTJyskJES9e/eWJIWHh2vAgAEaOXKkIiMjFRERoVGjRqlBgwaOu52LgiYRAADAi2zfvl1t27Z1PD+/nrFv375KT0/XmDFjlJOToyFDhujEiRNq1qyZ1q1bpzJlyjheM336dAUEBKhHjx7KyclRu3btlJ6eLn9//yLXYbMsy3Ldx/IOpeIf9XQJANzkp0+e93QJANykXEjRGxhXu2Pu52679tuDm7rt2u7EmkQAAAAYmG4GAAA+z51b4FyrSBIBAABgIEkEAAA+zyaixAvRJAIAAJ/nTVvgeAummwEAAGAgSQQAAD7PnT/Ld60iSQQAAICBJBEAAPg8gkQTSSIAAAAMJIkAAMDn+RElGkgSAQAAYCBJBAAAPo8g0USTCAAAfB5b4JiK1CS+8cYbRb5g165dr7gYAAAAeIciNYndunUr0sVsNpsKCgquph4AAIASR5BoKlKTWFhY6O46AAAA4EWuak3i2bNnFRwc7KpaAAAAPIItcEzF3gKnoKBAzzzzjCpVqqTSpUvr+++/lyQ9+eSTWrBggcsLBAAAQMkrdpM4adIkpaenKzU1VUFBQY7xBg0a6KWXXnJpcQAAACXB5sbHtarYTeLixYs1b9489enTR/7+/o7xm266Sd98841LiwMAAIBnFHtN4o8//qgaNWoY44WFhcrLy3NJUQAAACWJfRJNxU4S69Wrp82bNxvj//73vxUfH++SogAAAEqSn819j2tVsZPE5ORk3X///frxxx9VWFioVatWaf/+/Vq8eLHefPNNd9QIAACAElbsJLFLly565ZVX9Pbbb8tms+mpp57Svn37tHbtWnXo0MEdNQIAALiVzWZz2+NadUX7JHbq1EmdOnVydS0AAADwEle8mfb27du1b98+2Ww21alTRwkJCa6sCwAAoMRcw4Gf2xS7STxy5IjuvfdeffLJJypbtqwk6ddff1WLFi20YsUKxcbGurpGAAAAlLBir0ns37+/8vLytG/fPh0/flzHjx/Xvn37ZFmWBgwY4I4aAQAA3Io1iaZiJ4mbN2/Wli1bVLt2bcdY7dq1NWPGDLVs2dKlxQEAAMAzit0kxsXFXXTT7Pz8fFWqVMklRQEAAJSka3k/Q3cp9nRzamqqHnvsMW3fvl2WZUn6/SaWYcOGadq0aS4vEAAAwN2YbjYVKUksV66c04fMzs5Ws2bNFBDw+8vz8/MVEBCg/v37q1u3bm4pFAAAACWnSE1iWlqam8sAAADwnGs373OfIjWJffv2dXcdAAAA8CJXvJm2JOXk5Bg3sYSFhV1VQQAAACXN7xpeO+guxb5xJTs7W48++qgqVKig0qVLq1y5ck4PAAAAXPuK3SSOGTNGGzZs0OzZs2W32/XSSy9p4sSJiomJ0eLFi91RIwAAgFvZbO57XKuKPd28du1aLV68WG3atFH//v3VqlUr1ahRQ5UrV9ayZcvUp08fd9QJAACAElTsJPH48eOqWrWqpN/XHx4/flySdMstt2jTpk2urQ4AAKAEsE+iqdhNYrVq1XTw4EFJUt26dfXqq69K+j1hLFu2rCtrAwAAgIcUu0l88MEH9cUXX0iSxo0b51ibOHz4cI0ePdrlBQIAALgbaxJNxV6TOHz4cMfft23bVt988422b9+u6tWrq2HDhi4tDgAAoCSwBY6p2EniheLi4tS9e3dFRESof//+rqgJAAAAHnbVTeJ5x48f16JFi1x1OQAAgBLDdLPJZU0iAAAArh9X9bN8AAAA14NreasadyFJBAAAgKHISWL37t0ve/zXX3+92lpc5sS2mZ4uAYCbLNt52NMlAHCTAU3jPPbepGamIjeJ4eHhf3r8gQceuOqCAAAA4HlFbhJffvlld9YBAADgMaxJNHHjCgAA8Hl+9IgGpuABAABgIEkEAAA+jyTRRJIIAAAAA0kiAADwedy4YrqiJHHJkiVq2bKlYmJidOjQIUlSWlqa/vOf/7i0OAAAAHhGsZvEOXPmaMSIEbrjjjv066+/qqCgQJJUtmxZpaWlubo+AAAAt/Ozue9xrSp2kzhjxgzNnz9f48ePl7+/v2O8SZMm+uqrr1xaHAAAADyj2GsSMzIyFB8fb4zb7XZlZ2e7pCgAAICSxJJEU7GTxKpVq2r37t3G+DvvvKO6deu6oiYAAIAS5Wezue1xrSp2kjh69GgNHTpUZ8+elWVZ+vzzz7VixQqlpKTopZdeckeNAAAAKGHFThIffPBBJScna8yYMTpz5ox69+6tuXPn6vnnn1evXr3cUSMAAIBb+bnxURz5+fn65z//qapVq6pUqVKqVq2ann76aRUWFjrOsSxLEyZMUExMjEqVKqU2bdpo7969V/rRL+mK9kkcOHCgBg4cqGPHjqmwsFAVKlRwdV0AAAA+Z+rUqZo7d64WLVqkevXqafv27XrwwQcVHh6uYcOGSZJSU1P13HPPKT09XbVq1dKzzz6rDh06aP/+/SpTpozLarmqzbTLly/vqjoAAAA8xluWDm7dulV33XWXOnfuLEmqUqWKVqxYoe3bt0v6PUVMS0vT+PHj1b17d0nSokWLFBUVpeXLl2vQoEEuq6XYTWLVqlUvuyv5999/f1UFAQAAXE9yc3OVm5vrNGa322W3241zb7nlFs2dO1fffvutatWqpS+++EIff/yxYy/qjIwMZWZmqmPHjk7Xat26tbZs2eLZJjEpKcnpeV5ennbt2qV3331Xo0ePdlVdAAAAJcaddyGnpKRo4sSJTmPJycmaMGGCce7YsWN18uRJ3XjjjfL391dBQYEmTZqke++9V5KUmZkpSYqKinJ6XVRUlONX8Fyl2E3i+fnwC82aNcsRhQIAAOB348aN04gRI5zGLpYiStIrr7yipUuXavny5apXr552796tpKQkxcTEqG/fvo7zLpzVtSzL5b8/fUW/3XwxiYmJev311111OQAAgBJjs7nvYbfbFRYW5vS4VJM4evRo/eMf/1CvXr3UoEED3X///Ro+fLhSUlIkSdHR0ZL+f6J4XlZWlpEuXi2XNYmvvfaaIiIiXHU5AACAEuMtv9185swZ+fk5t2f+/v6OLXCqVq2q6OhorV+/3nH83Llz2rhxo1q0aHHV38MfFXu6OT4+3inOtCxLmZmZ+vnnnzV79myXFgcAAOBLunTpokmTJikuLk716tXTrl279Nxzz6l///6Sfp9mTkpK0uTJk1WzZk3VrFlTkydPVkhIiHr37u3SWordJHbr1s3puZ+fn/7yl7+oTZs2uvHGG11VFwAAQInxlp/PmzFjhp588kkNGTJEWVlZiomJ0aBBg/TUU085zhkzZoxycnI0ZMgQnThxQs2aNdO6detcukeiJNksy7KKenJ+fr6WLVumTp06OebEvdHZfE9XAMBdlu087OkSALjJgKZxHnvvp9cfcNu1n+pQw23XdqdirUkMCAjQI488Yuz1AwAAcC1z540r16pi37jSrFkz7dq1yx21AAAAwEsUe03ikCFDNHLkSB05ckQJCQkKDQ11On7TTTe5rDgAAICSUNy7kH1BkZvE/v37Ky0tTT179pQkPf74445jNpvNsYljQUGB66sEAABAiSpyk7ho0SJNmTJFGRkZ7qwHAACgxNlElHihIjeJ52+Crly5stuKAQAA8ASmm03FunHF1b8JCAAAAO9UrBtXatWq9aeN4vHjx6+qIAAAgJJGkmgqVpM4ceJEhYeHu6sWAAAAeIliNYm9evVShQoV3FULAACAR7CkzlTkNYl8eQAAAL6j2Hc3AwAAXG9Yk2gqcpNYWFjozjoAAADgRYr9s3wAAADXG1bVmWgSAQCAz/OjSzQUazNtAAAA+AaSRAAA4PO4ccVEkggAAAADSSIAAPB5LEk0kSQCAADAQJIIAAB8np+IEi9EkggAAAADSSIAAPB5rEk00SQCAACfxxY4JqabAQAAYCBJBAAAPo+f5TORJAIAAMBAkggAAHweQaKJJBEAAAAGkkQAAODzWJNoIkkEAACAgSQRAAD4PIJEE00iAADweUytmvhOAAAAYCBJBAAAPs/GfLOBJBEAAAAGkkQAAODzyBFNJIkAAAAwkCQCAACfx2baJpJEAAAAGEgSAQCAzyNHNNEkAgAAn8dss4npZgAAABhIEgEAgM9jM20TSSIAAAAMJIkAAMDnkZqZ+E4AAABgIEkEAAA+jzWJJpJEAAAAGEgSAQCAzyNHNJEkAgAAwECSCAAAfB5rEk00iQAAwOcxtWriOwEAAICBJBEAAPg8pptNJIkAAAAwkCQCAACfR45oIkkEAACAgSQRAAD4PJYkmkgSAQAAYCBJBAAAPs+PVYkGmkQAAODzmG42Md0MAADgRX788Ufdd999ioyMVEhIiBo1aqQdO3Y4jluWpQkTJigmJkalSpVSmzZttHfvXpfXQZMIAAB8ns2NfxXHiRMn1LJlSwUGBuqdd97R119/rX/9618qW7as45zU1FQ999xzmjlzprZt26bo6Gh16NBBv/32m0u/E6abAQAAvMTUqVMVGxurl19+2TFWpUoVx99blqW0tDSNHz9e3bt3lyQtWrRIUVFRWr58uQYNGuSyWkgSAQCAz7PZ3PfIzc3VqVOnnB65ubkXreONN95QkyZNdM8996hChQqKj4/X/PnzHcczMjKUmZmpjh07Osbsdrtat26tLVu2uPQ7oUkEAABwo5SUFIWHhzs9UlJSLnru999/rzlz5qhmzZp67733NHjwYD3++ONavHixJCkzM1OSFBUV5fS6qKgoxzFXYboZAAD4PHdugTNu3DiNGDHCacxut1/03MLCQjVp0kSTJ0+WJMXHx2vv3r2aM2eOHnjgAcd5tgtux7Ysyxi7WiSJAAAAbmS32xUWFub0uFSTWLFiRdWtW9dprE6dOjp8+LAkKTo6WpKM1DArK8tIF68WTSIAAPB57lyTWBwtW7bU/v37nca+/fZbVa5cWZJUtWpVRUdHa/369Y7j586d08aNG9WiRYur/h7+iOlmAADg87xlM+3hw4erRYsWmjx5snr06KHPP/9c8+bN07x58yT9Ps2clJSkyZMnq2bNmqpZs6YmT56skJAQ9e7d26W10CQCAAB4iZtvvlmrV6/WuHHj9PTTT6tq1apKS0tTnz59HOeMGTNGOTk5GjJkiE6cOKFmzZpp3bp1KlOmjEtrsVmWZbn0il7gbL6nKwDgLst2HvZ0CQDcZEDTOI+99/p9x9x27Q51yrvt2u7EmkQAAAAYmG4GAAA+z89L1iR6E5JEAAAAGEgSAQCAz7O5cTPtaxVJIgAAAAwkiQAAwOd5yz6J3oQmEQAA+Dymm01MNwMAAMBAkggAAHweW+CYSBIBAABgIEkEAAA+jzWJJpJEAAAAGEgS4fUWzH9RH6xfp4yM72UPDlajRvFKGjFKVapWkyTl5eVp5gtp+njzJh058oPKlC6tZs1baNjwkapQIcrD1QP4M3OH36dTx/5njMe366IO/R6XZVn6ZPUSffHhW8rNPq2K1W9Uh76PqfwNVUq+WFy32ALHRJMIr7d92+fqeW8f1WvQQAX5BZrxwnQNHjhAq954SyEhITp79qy+2fe1Hh78iGrXvlGnTp1S6pTJGvboI1rx6ipPlw/gTzwwcaYKCwsdz48dOahXp45V7WatJUmfv/WKtr/zuu54eJTKRd+grf9ZrlemjtVDqS/LXirEU2UD1z2bZVmWp4twtbP5nq4A7nT8+HG1bdVcCxctVUKTmy96zp6vvlSfXvfo3fUfqmJMTAlXCHdatvOwp0uAm32wdLb+u+szDZyWLkma/VgvNbn9b2p2Zy9JUn7eOc16tIda93xIjW6704OVwtUGNI3z2Ht/8t0Jt127Zc1ybru2O3k0STxy5IjmzJmjLVu2KDMzUzabTVFRUWrRooUGDx6s2NhYT5YHL3X6t98kSWHh4Zc+5/Rp2Ww2lQkLK6myALhAQX6evv7kAzVJvFs2m02/Zh1V9snjqlK/ieOcgMAgxd54k3787muaRLiMH/PNBo81iR9//LESExMVGxurjh07qmPHjrIsS1lZWVqzZo1mzJihd955Ry1btrzsdXJzc5Wbm+s0ZvnbZbfb3Vk+PMSyLE1LTVF84wTVrFnroufk5ubq+enTlNj5TpUuXbqEKwRwNb7bsUVnz5xW/VYdJUnZvx6XJIWEl3U6LySsnE79Yq5jBOA6HmsShw8froceekjTp0+/5PGkpCRt27btstdJSUnRxIkTncbGP5msfz41wVWlwoukPPu0vvv2W6UvWX7R43l5eRo7argKCy2Nf3JCyRYH4Kp9ufEdVbupqcqUK+80bjNSHostS+BS/NNk8tgWOHv27NHgwYMveXzQoEHas2fPn15n3LhxOnnypNNj9NhxriwVXiJl0jP66KMNmv/yIkVFRxvH8/LyNHpkkn48ckQvvrSQFBG4xpw89j8d2rNLN7VJdIyFlo2QJGX/6rxe7MypXxUSfm2u8wKuFR5rEitWrKgtW7Zc8vjWrVtVsWLFP72O3W5XWFiY04Op5uuLZVma/OzT+uD9dZq/cJFuuMFcq3q+QTx86JBeXJCusmX5jwdwrflq03sKCSur6o2aOcbC/xKt0PAIHdyzwzFWkJ+nH775UpVq1vVEmbhe2dz4uEZ5bLp51KhRGjx4sHbs2KEOHTooKipKNptNmZmZWr9+vV566SWlpaV5qjx4kcnPTNQ7b7+ptBmzFRoSqmM//yxJKl2mjIKDg5Wfn69Rwx/Xvn1fa8asF1VYUOA4Jzw8XIFBQZ4sH0ARWIWF2rPpPdVv1UF+/v6OcZvNpia3/02frl2hctGVVC6qkj5du0IBQXbVaX6bBysGrn8eaxKHDBmiyMhITZ8+XS+++KIKCgokSf7+/kpISNDixYvVo0cPT5UHL/LqKyskSQP63e80/vSzKbrrb931v/9l6qMPN0iSetx9l9M5L728WDc3bSYA3u3g3p069UuWGtx6u3Gsaeeeyjt3TuvTZ+jsmd9UsdqN6jFmCnskwqVY42ryin0S8/LydOzYMUlS+fLlFRgYeFXXY59E4PrFPonA9cuT+yR+9t+Tbrt2s+qX3rLNm3nFL64EBgYWaf0hAACAO7BNoskrmkQAAABPokc0eezuZgAAAHgvkkQAAACiRANJIgAAAAwkiQAAwOexBY6JJBEAAAAGkkQAAODz2ALHRJIIAAAAA0kiAADweQSJJppEAAAAukQD080AAAAwkCQCAACfxxY4JpJEAAAAGEgSAQCAz2MLHBNJIgAAAAwkiQAAwOcRJJpIEgEAAGAgSQQAACBKNNAkAgAAn8cWOCammwEAAGAgSQQAAD6PLXBMJIkAAAAwkCQCAACfR5BoIkkEAACAgSQRAACAKNFAkggAAAADSSIAAPB57JNoIkkEAACAgSQRAAD4PPZJNNEkAgAAn0ePaGK6GQAAAAaSRAAAAKJEA0kiAAAADCSJAADA57EFjokkEQAAAAaSRAAA4PPYAsdEkggAAAADSSIAAPB5BIkmmkQAAAC6RAPTzQAAAF4qJSVFNptNSUlJjjHLsjRhwgTFxMSoVKlSatOmjfbu3evy96ZJBAAAPs/mxr+u1LZt2zRv3jzddNNNTuOpqal67rnnNHPmTG3btk3R0dHq0KGDfvvtt6v9GpzQJAIAAHiZ06dPq0+fPpo/f77KlSvnGLcsS2lpaRo/fry6d++u+vXra9GiRTpz5oyWL1/u0hpoEgEAgM+z2dz3yM3N1alTp5weubm5l61n6NCh6ty5s9q3b+80npGRoczMTHXs2NExZrfb1bp1a23ZssWl3wlNIgAAgBulpKQoPDzc6ZGSknLJ81euXKmdO3de9JzMzExJUlRUlNN4VFSU45ircHczAADwee68uXncuHEaMWKE05jdbr/ouT/88IOGDRumdevWKTg4+JLXtF2w+7dlWcbY1aJJBAAAcCO73X7JpvBCO3bsUFZWlhISEhxjBQUF2rRpk2bOnKn9+/dL+j1RrFixouOcrKwsI128Wkw3AwAA2Nz4KIZ27drpq6++0u7dux2PJk2aqE+fPtq9e7eqVaum6OhorV+/3vGac+fOaePGjWrRosUVf/yLIUkEAAA+72q2qnGlMmXKqH79+k5joaGhioyMdIwnJSVp8uTJqlmzpmrWrKnJkycrJCREvXv3dmktNIkAAADXkDFjxignJ0dDhgzRiRMn1KxZM61bt05lypRx6fvYLMuyXHpFL3A239MVAHCXZTsPe7oEAG4yoGmcx94749hZt127avlL34DizViTCAAAAAPTzQAAwOd5x4pE70KSCAAAAANJIgAAAFGigSQRAAAABpJEAADg87xln0RvQpMIAAB8not/9vi6wHQzAAAADCSJAADA5xEkmkgSAQAAYCBJBAAAPo81iSaSRAAAABhIEgEAAFiVaCBJBAAAgIEkEQAA+DzWJJpoEgEAgM+jRzQx3QwAAAADSSIAAPB5TDebSBIBAABgIEkEAAA+z8aqRANJIgAAAAwkiQAAAASJBpJEAAAAGEgSAQCAzyNINNEkAgAAn8cWOCammwEAAGAgSQQAAD6PLXBMJIkAAAAwkCQCAAAQJBpIEgEAAGAgSQQAAD6PINFEkggAAAADSSIAAPB57JNookkEAAA+jy1wTEw3AwAAwECSCAAAfB7TzSaSRAAAABhoEgEAAGCgSQQAAICBNYkAAMDnsSbRRJIIAAAAA0kiAADweeyTaKJJBAAAPo/pZhPTzQAAADCQJAIAAJ9HkGgiSQQAAICBJBEAAIAo0UCSCAAAAANJIgAA8HlsgWMiSQQAAICBJBEAAPg89kk0kSQCAADAQJIIAAB8HkGiiSYRAACALtHAdDMAAAAMJIkAAMDnsQWOiSQRAAAABpJEAADg89gCx0SSCAAAAIPNsizL00UAVyo3N1cpKSkaN26c7Ha7p8sB4EL8+QY8iyYR17RTp04pPDxcJ0+eVFhYmKfLAeBC/PkGPIvpZgAAABhoEgEAAGCgSQQAAICBJhHXNLvdruTkZBa1A9ch/nwDnsWNKwAAADCQJAIAAMBAkwgAAAADTSIAAAAMNIkAAAAw0CTimrRp0yZ16dJFMTExstlsWrNmjadLAuBis2fPVtWqVRUcHKyEhARt3rzZ0yUBPoUmEdek7OxsNWzYUDNnzvR0KQDc4JVXXlFSUpLGjx+vXbt2qVWrVkpMTNThw4c9XRrgM9gCB9c8m82m1atXq1u3bp4uBYCLNGvWTI0bN9acOXMcY3Xq1FG3bt2UkpLiwcoA30GSCADwKufOndOOHTvUsWNHp/GOHTtqy5YtHqoK8D00iQAAr3Ls2DEVFBQoKirKaTwqKkqZmZkeqgrwPTSJAACvZLPZnJ5blmWMAXAfmkQAgFcpX768/P39jdQwKyvLSBcBuA9NIgDAqwQFBSkhIUHr1693Gl+/fr1atGjhoaoA3xPg6QKAK3H69GkdOHDA8TwjI0O7d+9WRESE4uLiPFgZAFcYMWKE7r//fjVp0kTNmzfXvHnzdPjwYQ0ePNjTpQE+gy1wcE366KOP1LZtW2O8b9++Sk9PL/mCALjc7NmzlZqaqqNHj6p+/fqaPn26br31Vk+XBfgMmkQAAAAYWJMIAAAAA00iAAAADDSJAAAAMNAkAgAAwECTCAAAAANNIgAAAAw0iQAAADDQJAIAAMBAkwjAZSZMmKBGjRo5nvfr10/dunUr8ToOHjwom82m3bt3u+09LvysV6Ik6gSAK0WTCFzn+vXrJ5vNJpvNpsDAQFWrVk2jRo1Sdna229/7+eefL/LPJJZ0w9SmTRslJSWVyHsBwLUowNMFAHC/22+/XS+//LLy8vK0efNmPfTQQ8rOztacOXOMc/Py8hQYGOiS9w0PD3fJdQAAJY8kEfABdrtd0dHRio2NVe/evdWnTx+tWbNG0v+fNl24cKGqVasmu90uy7J08uRJPfzww6pQoYLCwsJ022236YsvvnC67pQpUxQVFaUyZcpowIABOnv2rNPxC6ebCwsLNXXqVNWoUUN2u11xcXGaNGmSJKlq1aqSpPj4eNlsNrVp08bxupdffll16tRRcHCwbrzxRs2ePdvpfT7//HPFx8crODhYTZo00a5du676Oxs7dqxq1aqlkJAQVatWTU8++aTy8vKM81588UXFxsYqJCRE99xzj3799Ven439WOwB4K5JEwAeVKlXKqeE5cOCAXn31Vb3++uvy9/eXJHXu3FkRERF6++23FR4erhdffFHt2rXTt99+q4iICL366qtKTk7WrFmz1KpVKy1ZskQvvPCCqlWrdsn3HTdunObPn6/p06frlltu0dGjR/XNN99I+r3Ra9q0qd5//33Vq1dPQUFBkqT58+crOTlZM2fOVHx8vHbt2qWBAwcqNDRUffv2VXZ2tu68807ddtttWrp0qTIyMjRs2LCr/o7KlCmj9PR0xcTE6KuvvtLAgQNVpkwZjRkzxvje1q5dq1OnTmnAgAEaOnSoli1bVqTaAcCrWQCua3379rXuuusux/PPPvvMioyMtHr06GFZlmUlJydbgYGBVlZWluOcDz74wAoLC7POnj3rdK3q1atbL774omVZltW8eXNr8ODBTsebNWtmNWzY8KLvferUKctut1vz58+/aJ0ZGRmWJGvXrl1O47Gxsdby5cudxp555hmrefPmlmVZ1osvvmhFRERY2dnZjuNz5sy56LX+qHXr1tawYcMuefxCqampVkJCguN5cnKy5e/vb/3www+OsXfeecfy8/Ozjh49WqTaL/WZAcAbkCQCPuDNN99U6dKllZ+fr7y8PN11112aMWOG43jlypX1l7/8xfF8x44dOn36tCIjI52uk5OTo//+97+SpH379mnw4MFOx5s3b64PP/zwojXs27dPubm5ateuXZHr/vnnn/XDDz9owIABGjhwoGM8Pz/fsd5x3759atiwoUJCQpzquFqvvfaa0tLSdODAAZ0+fVr5+fkKCwtzOicuLk433HCD0/sWFhZq//798vf3/9PaAcCb0SQCPqBt27aaM2eOAgMDFRMTY9yYEhoa6vS8sLBQFStW1EcffWRcq2zZsldUQ6lSpYr9msLCQkm/T9s2a9bM6dj5aXHLsq6onsv59NNP1atXL02cOFGdOnVSeHi4Vq5cqX/961+XfZ3NZnP8b1FqBwBvRpMI+IDQ0FDVqFGjyOc3btxYmZmZCggIUJUqVS56Tp06dfTpp5/qgQcecIx9+umnl7xmzZo1VapUKX3wwQd66KGHjOPn1yAWFBQ4xqKiolSpUiV9//336tOnz0WvW7duXS1ZskQ5OTmORvRydRTFJ598osqVK2v8+PGOsUOHDhnnHT58WD/99JNiYmIkSVu3bpWfn59q1apVpNoBwJvRJAIwtG/fXs2bN1e3bt00depU1a5dWz/99JPefvttdevWTU2aNNGwYcPUt29fNWnSRLfccouWLVumvXv3XvLGleDgYI0dO1ZjxoxRUFCQWrZsqZ9//ll79+7VgAEDVKFCBZUqVUrvvvuubrjhBgUHBys8PFwTJkzQ448/rrCwMCUmJio3N1fbt2/XiRMnNGLECPXu3Vvjx4/XgAED9M9//lMHDx7UtGnTivQ5f/75Z2NfxujoaNWoUUOHDx/WypUrdfPNN+utt97S6tWrL/qZ+vbtq2nTpunUqVN6/PHH1aNHD0VHR0vSn9YOAF7N04siAbjXhTeuXCg5OdnpZpPzTp06ZT322GNWTEyMFRgYaMXGxlp9+vSxDh8+7Dhn0qRJVvny5a3SpUtbffv2tcaMGXPJG1csy7IKCgqsZ5991qpcubIVGBhoxcXFWZMnT3Ycnz9/vhUbG2v5+flZrVu3dowvW7bMatSokRUUFGSVK1fOuvXWW61Vq1Y5jm/dutVq2LChFRQUZDVq1Mh6/fXXi3TjiiTjkZycbFmWZY0ePdqKjIy0SpcubfXs2dOaPn26FR4ebnxvs2fPtmJiYqzg4GCre/fu1vHjx53e53K1c+MKAG9msyw3LOgBAADANY3NtAEAAGCgSQQAAICBJhEAAAAGmkQAAAAYaBIBAABgoEkEAACAgSYRAAAABppEAAAAGGgSAQAAYKBJBAAAgIEmEQAAAIb/B04VWq3yYLp2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_pred, test_y), annot=True, fmt='d', cmap='Blues', xticklabels=test_y.unique(), yticklabels=test_y.unique())\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.792\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(test_y, y_pred)\n",
    "print('AUC: %.3f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: logistic and Solver: lbfgs, Accuracy: 0.7761\n",
      "Activation: logistic and Solver: sgd, Accuracy: 0.7985\n",
      "Activation: logistic and Solver: adam, Accuracy: 0.7873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: tanh and Solver: lbfgs, Accuracy: 0.7985\n",
      "Activation: tanh and Solver: sgd, Accuracy: 0.8060\n",
      "Activation: tanh and Solver: adam, Accuracy: 0.8134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: relu and Solver: lbfgs, Accuracy: 0.7724\n",
      "Activation: relu and Solver: sgd, Accuracy: 0.8396\n",
      "Activation: relu and Solver: adam, Accuracy: 0.8284\n"
     ]
    }
   ],
   "source": [
    "# Train MLPClassifier with different activation functions\n",
    "activation_functions = ['logistic', 'tanh', 'relu']\n",
    "solver_alg = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "for activation in activation_functions:\n",
    "    for solv in solver_alg:\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(100,), activation=activation, solver=solv, max_iter=1000, random_state=42)\n",
    "        mlp.fit(train_X, train_y)\n",
    "    \n",
    "        # Make predictions\n",
    "        y_pred = mlp.predict(test_X)\n",
    "    \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(test_y, y_pred)\n",
    "        print(f\"Activation: {activation} and Solver: {solv}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
